{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62449670",
   "metadata": {},
   "source": [
    "# Basics of Mobile Robotics - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d1c06e",
   "metadata": {},
   "source": [
    "**Students: Cécile Chavane, Yucef Grebici, Camille Guillaume, Théo Hermann**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9c65a7",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "\n",
    "<div class=\"toc\"><ul class=\"toc-item\">\n",
    "    <li><span><a href=\"#Introduction\" data-toc-modified-id=\">Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Project-description\" data-toc-modified-id=\"Project-description-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Project description</a></span></li>\n",
    "        <li><span><a href=\"#Environment-Setup\" data-toc-modified-id=\"Environment-Setup-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Environment Setup</a></span></li>\n",
    "        <li><span><a href=\"#Libraries-Import\" data-toc-modified-id=\"Libraires-Import-1.2\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Libraries Import</a></span></li>\n",
    "        <li><span><a href=\"#Thymio COnnection\" data-toc-modified-id=\"Thymio-Connection-1.3\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Thymio Connection</a></span></li>\n",
    "        </ul></li>\n",
    "    <li><span><a href=\"#Description-of-the-modules\" data-toc-modified-id=\"Description-of-the-modules-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Description of the Modules</a></span><ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Vision\" data-toc-modified-id=\"Vision-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Vision</a></span></li>\n",
    "        <li><span><a href=\"#Global-Navigation\" data-toc-modified-id=\"Global-Navigation-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Global Navigation</a></span></li>\n",
    "        <li><span><a href=\"#Local-Navigation\" data-toc-modified-id=\"Local-Navigation-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Local Navigation</a></span></li>\n",
    "        <li><span><a href=\"#Filtering\" data-toc-modified-id=\"Filtering-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Filtering</a></span></li>\n",
    "        <li><span><a href=\"#Motion-Control\" data-toc-modified-id=\"Motion-Control-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Motion Control</a></span></li>\n",
    "        </ul></li>\n",
    "    <li><span><a href=\"#Code-of-the-overall-project\" data-toc-modified-id=\"Code-of-the-overall-project-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Code of the overall project</a></span></li>\n",
    "    <li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Conclusion</a></span>\n",
    "    </li></ul>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f53c67",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Project description \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd74ae0",
   "metadata": {},
   "source": [
    "**Guidelines:**\n",
    "\n",
    "\n",
    "**Implementation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57061bde",
   "metadata": {},
   "source": [
    "## Environment  Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad25f54",
   "metadata": {},
   "source": [
    "Description of the environment , obstacles,corners, start/goal, wireless thymio, camera position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f44a9f",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"pics/environment.jpeg\" width=\"500\" alt=\"Environment\" />\n",
    "  <figcaption> <center> <u>Figure 1:</u> Picture of the environment setup with lightning <center> </figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "\n",
    "<!-- Commentaire : <img src=\"pics/environment.jpeg\" width=\"500\"/> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d786fd5",
   "metadata": {},
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkez ceux qui sont réellement nécéssaires\n",
    "import numpy as np\n",
    "import pyvisgraph as vg\n",
    "import math\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries\n",
    "from shapely.geometry import Polygon, Point, LineString\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0f2c8",
   "metadata": {},
   "source": [
    "## Thymio Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#communication asynchrone avec thymio\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a5bac",
   "metadata": {},
   "source": [
    "# Description of the modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e79f70",
   "metadata": {},
   "source": [
    "We separated our code in different python file containing the functions for each module. We will import all the python files below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Vision as vis\n",
    "import Global as glob\n",
    "import local_nav as loc\n",
    "#import Filtering as fil\n",
    "import control as ctrl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a35fc",
   "metadata": {},
   "source": [
    "<span style=\"color: darkblue\"> TO REMOVE \n",
    "What is important is not to simply describe the code, which should be readable, but describe what is not in the code: the theory behind, the choices made, the measurements, the choice of parameters etc. Do not forget to cite your sources ! You can of course show how certain modules work in simulation here, or with pre-recorded data.</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f9d35",
   "metadata": {},
   "source": [
    "## Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ec3c1",
   "metadata": {},
   "source": [
    " First we verified vision parameters, like HSV color range, erode_iterations and area_size, by running the notebook Vision Calibration. It allows us to be robust against change of luminosity. \n",
    "\n",
    "1. Image calibration\n",
    "\n",
    "2. Detection objets (obstacles, start, goal)\n",
    "\n",
    "3. Detection thymio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e5a12",
   "metadata": {},
   "source": [
    "| Function of Vision | Input | Output |\n",
    "|------|------|------|\n",
    "|   _img_calibration(img)_  | (Raw image from camera) | (Transformed image with only the zone of arena)\n",
    "|   _order_points(corner_points)_  | (Transformed image) | (Raw obstacle mask, Thymio start, Thymio target, Thymio pose)\n",
    "|   _four_point_transform(img,corner_points)_  | (Raw obstacle mask, dilate diameter in pixel) | (Obstacle mask dilated with the Thymio radius and corrected with the walls(drawer bounds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80899daa",
   "metadata": {},
   "source": [
    "| Main OpenCv function| Goal | Used in |\n",
    "|------|------|------|\n",
    "|   `cv2.erode(mask,None, iterations_erode)` and `cv2.dilate(mask_final,None, iterations_erode)`| Are used to make the mask more robust to noise and to remove parasitic elements |`img_calibration(img)`,`detectCircle()`,`obstacle_detection()`|\n",
    "|   `cv2.findContours(mask_final, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)`   | Detect the points that form the countours of an object |`img_calibration(img)`,`detectCircle()`,`obstacle_detection()`|\n",
    "|   `cv2.moments(contours[i])`   | Is use to find the center of the four corners |`img_calibration(img)`|\n",
    "|   `cv2.contourArea(contours[backwards_i])`   | Return the area size of an objects form by the contours |`img_calibration(img)`,`detectCircle()`,`obstacle_detection()`|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = vis.takePicture(1)\n",
    "env = cv2.cvtColor(env, cv2.COLOR_BGR2RGB)\n",
    "plt.figure()\n",
    "plt.imshow(env)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbee050",
   "metadata": {},
   "source": [
    "We first apply a green mask to our frame in order to detect the center of the four green square who represents the corners of our map. \n",
    "\n",
    "We saw that we had some noise by simply implementing a classic green mask so we add some steps to improve the quality of the detection. To begin we apply a Gaussian blur to the frame, then we create the green mask and to improve the mask we used two OpenCv functions `erode` and `dilate` to remove the noise on the mask and only detect the four corners. \n",
    "\n",
    "The main variable that influence the quality of the detection are green_lower and green_upper that are used to create the green mask and also the variable iterations that modify the effect of the function erode and dilate. In order to be robust to the variation of luminosity we had create a notebook \"pre-run calibration\" to prevent errors and verified the variable of vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3cfb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations=4\n",
    "green_lower=np.array([30,40,40])\n",
    "green_upper=np.array([80,255,255])\n",
    "\n",
    "env_blur = cv2.GaussianBlur(env, (7, 7), 0)\n",
    "env_hsv = cv2.cvtColor(env_blur, cv2.COLOR_RGB2HSV)\n",
    "mask = cv2.inRange(env_hsv, green_lower, green_upper)\n",
    "mask_final = cv2.erode(mask,None, iterations)\n",
    "mask_final = cv2.dilate(mask_final,None, iterations)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2,figsize=(10, 8))\n",
    "ax[0].imshow(mask)\n",
    "ax[1].imshow(mask_final)\n",
    "ax[0].set_title(\"Mask without erode and dilate\")\n",
    "ax[1].set_title(\"Mask with erode and dilate\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30fe95",
   "metadata": {},
   "source": [
    "Then we detect the centers of the four green square with the OpenCV function **findContours** and **moments**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_size=50\n",
    "contours, hierarchy = cv2.findContours(mask_final, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n",
    "#suppressing false corners\n",
    "initial_length=len(contours)\n",
    "for i in range(len(contours)):\n",
    "    backwards_i=initial_length-i-1\n",
    "    area = cv2.contourArea(contours[backwards_i])\n",
    "    # Shortlisting the regions based on there area.\n",
    "    if area < area_size:\n",
    "        del contours[backwards_i]\n",
    "#finding corners center\n",
    "corner_points = []\n",
    "for i in range(len(contours)):\n",
    "    if (cv2.contourArea(contours[i]) > area_size):\n",
    "        mom = cv2.moments(contours[i])\n",
    "        corner_points.append((int(mom['m10'] / mom['m00']), int(mom['m01'] / mom['m00']))) #centre des carrés\n",
    "if len(corner_points) != 4:\n",
    "    print(\"failure in identifying corners\")\n",
    "print(corner_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2459b",
   "metadata": {},
   "source": [
    "After that we create a function **order_points** that return the points found before in the right order for the calibration. The output order is top left, top right, bottom left, bottom right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e96556",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_points=vis.order_points(corner_points)\n",
    "print(corner_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6dc8eb",
   "metadata": {},
   "source": [
    "Finally our function **four_point_transform** adapt the image to the corner of the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f37e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "warpedenv=vis.four_point_transform(env,corner_points)\n",
    "plt.figure()\n",
    "plt.imshow(warpedenv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3e2d9",
   "metadata": {},
   "source": [
    "Here is the exemple of the total function of calibration, **img_calibration**, that takes the frame from the camera in input and return the new image representing our map. This function act as shown above : apply a mask, find corners coordinates, reorder them and recalibrate image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acace6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "warpedenv_vis = vis.img_calibration(env.copy())\n",
    "plt.figure()\n",
    "plt.imshow(warpedenv_vis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405c8116",
   "metadata": {},
   "source": [
    "## Global Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c560b",
   "metadata": {},
   "source": [
    "During the initialization of the global path given to the robot we call the high level global_pathplanning function that implements the visibility graph algorithm. Here after are the different steps of this function.\n",
    "We use two libraries for this purpose:\n",
    "\n",
    "pyvisgraph for the visibility Graph algorithm: https://github.com/TaipanRex/pyvisgraph\n",
    "- Algorithm: Given a set of simple obstacle polygons, build a visibility graph and find the shortest path between two points.\n",
    "- The visibility graph algorithm (D.T. Lee) runs in O(n^2 log n) time. \n",
    "- The shortest path is found using Djikstra's algorithm.\n",
    "\n",
    "geopanda to manage geometric data: https://geopandas.org/en/stable/docs/reference/geoseries.html\n",
    "- Geometric library that allows to use data of geometric type: Geoseries, polygons, points and to manage this geometric data: plotting, adding marging, input to the visibility graph functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98cf32e",
   "metadata": {},
   "source": [
    "Here we will define some example polygons that represent the obstacles, and example start and goal positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d00d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "p1 = [(1, 0), (2, 0), (2, 1.5), (1, 1.5)]\n",
    "p3 = [(3, 3), (4, 3), (4, 4), (3, 4)]\n",
    "list_obstacles=[p1,p3]\n",
    "start_point=[0.0,0.0]\n",
    "end_point=[4.5, 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a119db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert this polygone list into a geometric set of polygons\n",
    "g_without_margin = glob.obstacles_to_polygons(list_obstacles)\n",
    "glob.plot_geometric_data(g_without_margin)\n",
    "\n",
    "# We add a margin to the obstacles related to the thymio's size, here 0.2 as example\n",
    "margin=0.2 \n",
    "g = glob.polygons_add_margin(g_without_margin,margin)\n",
    "glob.plot_geometric_data(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5efb64b",
   "metadata": {},
   "source": [
    "We apply the visibility graph algorithm to this geometric set of Polygons representing the obstacles and compute the shortest path from start to goal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visibility graph creation based on the corners of obstacles with margin\n",
    "visgraph = glob.polygons_to_VisibilityGraph(g)\n",
    "\n",
    "# Computation of the shortest path of the visibility graph with Djikstra algorithm\n",
    "shortest_path = glob.VisibilityGraph_shortest_path(visgraph, start_point, end_point)\n",
    "print(\"Shortest path: \", shortest_path)\n",
    "distance = glob.path_distance(shortest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df1d21",
   "metadata": {},
   "source": [
    "We convert this shortest path between start and goal into the geometric type and plot the resulting global path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18bcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.ShortestPath_to_geometric(shortest_path)\n",
    "\n",
    "# We plot the geometric data set with both the path and the obstacles\n",
    "g = g.geometry.append(g_without_margin)\n",
    "g = g.geometry.append(path.geometry)\n",
    "glob.plot_geometric_data(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c363d2",
   "metadata": {},
   "source": [
    "Finally we convert this geometric path into a vector which will be given to the main and will correspond to the path steps that the robot will follow if there is no local avoidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=glob.geometric_path_to_vector(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94e03f",
   "metadata": {},
   "source": [
    "## Local Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e21e1",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc18af",
   "metadata": {},
   "source": [
    "## Motion Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491bd40b",
   "metadata": {},
   "source": [
    "# Code of the overall Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e4aadd",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1dc1b1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
